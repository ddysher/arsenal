##### 5.1 TensorFlow单机程序编程框架

本节介绍TensorFlow单机程序的编程框架。我们从代码开发视角切入，将TensorFlow数据流图中的各种元素和概念映射到一个典型的单机程序——MNIST softmax模型的训练与推理程序。通过本节的学习，读者能够掌握TensorFlow单机程序编程框架的工作流程和使用方法。

###### 5.1.1 单机程序编程框架概述

单机程序是指启动和运行都仅在一台机器的一个进程中完成的程序。这种程序的模型参数只在本地CPU和/或GPU的内存之间传输，没有网络通信的开销，非常适合参数不多、计算量小的模型。相比分布式程序，单机程序的设计更加简单，编程难度更低，有利于新手快速入门。

图5-1展示了使用TensorFlow单机程序编程框架的关键步骤。以开发流程中操作的核心对象为依据，编写单机程序主要分为创建单机数据流图（Graph）和创建单机会话（DirectSession）两步：

- Graph：创建单机数据流图（模型）。数据流图主要由3类节点组成，分别是表示输入数据集的占位符（placeholder）、保存模型参数的变量（Variable），以及前向图和后向图中计算操作（Operation）。
- DirectSession：创建并运行单机会话。会话中执行的操作具体包括变量的初始化操作（init_op）、模型的恢复和保存操作、单步推理（inference_op）和单步训练（train_op）操作等。

![5_1](images/5_1.png)

图5-1 使用TensorFlow单机程序编程框架的关键步骤

TensorFlow单机程序的计算形态主要分为推理（预测）态和训练态。前者仅执行推理操作，计算得到推理或预测结果；后者依次执行前向图的推理计算和后向图的梯度计算，并完成模型参数的更新。

TensorFlow单机程序处理的数据主要分为3类，分别是来自于文件系统的输入数据集、从checkpoint文件恢复的模型参数和从命令行解析的模型超参数。在数据流图中，它们分别使用张量、变量和FLAGS名字空间来保存。在会话中，它们作为输入数据分别传输给操作、Saver和优化器这3类数据消费者。其中，操作定义了张量间的运算，如矩阵相乘、激活函数、神经网络层等。操作之间有可能存在依赖控制，用于管理多个操作的逻辑先后关系，确保以正确的时序执行各个操作。Saver负责管理checkpoint文件。它能够从checkpoint文件中恢复模型参数到变量，或者将变量中的模型参数保存到checkpoint文件。优化器负责计算梯度和更新模型参数。常见的优化器有SGD、Adam、Adagrad、Adadelta等。表5-1对比了TensorFlow单机程序处理的3类数据的类别、来源、载体和消费者间的映射关系。

表5-1 TensorFlow单机程序处理的3类数据

| 数据类别  | 数据来源         | 数据载体      | 数据消费者 |
| ----- | ------------ | --------- | ----- |
| 输入数据集 | 文件系统         | 张量        | 操作    |
| 模型参数  | checkpoint文件 | 变量        | Saver |
| 模型超参数 | 命令行          | FLAGS名字空间 | 优化器   |

###### 5.1.3 创建单机数据流图

对于深度学习和机器学习程序来说，模型是程序的主体。模型本身由数据流图中的节点组成，节点具体包括表示输入数据集的占位符、保存模型参数的变量，以及定义前向图和后向图的计算操作等。创建数据流图是使用TensorFlow单机程序编程框架的第一个关键步骤。下面我们介绍创建数据流图的具体步骤和方法。

TensorFlow内部会为当前程序的上下文维护一个默认的数据流图实例。同时，TensorFlow也允许用户在程序中显式创建多个数据流图实例。如果希望显式创建数据流图，并指定特定的数据流图为当前上下文的默认数据流图，那么可以使用以下代码实现。

```python
# 创建数据流图g1
g1 = tf.Graph()
with g1.as_default():
    # 在该上下文中，默认使用数据流图g1
    a = tf.Variable(0, name='a')
    # 断言变量a被添加到数据流图g1中
    assert a.graph is g1
# 创建数据流图g2
with tf.Graph().as_default() as g2:
    # 在该上下文中，默认使用数据流图g2
    b = tf.Variable(0, name='b')
    # 断言变量b被添加到数据流图g2中
    assert b.graph is g2
```

tf.Graph方法返回新建的数据流图实例，后者的as_default成员方法将自身设置为当前上下文的默认数据流图。用户可以使用with语句管理不同数据流图实例的上下文环境。所有操作实例都实现了graph成员方法，用于获取当前操作所属的数据流图。因此，我们可以使用断言语句判断变量a和b是否被分别添加到了数据流图g1和g2中。

如果用户没有显式创建数据流图实例，那么程序使用的将是TensorFlow内部创建的默认数据流图实例。在这种情况下，用户定义的所有操作都会被添加到默认实例中。下面展示的MNIST softmax模型的数据流图创建代码即为这种情况。

```python
"""5.1_best_practice.py"""
# -*- coding: utf-8 -*-
from tensorflow.examples.tutorials.mnist import input_data
import tensorflow as tf

flags = tf.app.flags
flags.DEFINE_string("data_dir", "/tmp/mnist-data",
                    "Directory for storing mnist data")
flags.DEFINE_float("learning_rate", 0.5, "Learning rate")
FLAGS = flags.FLAGS

def main(_):
  # 创建MNIST数据集实例
  mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)
  # 创建模型
  x = tf.placeholder(tf.float32, [None, 784])	# 图像数据
  W = tf.Variable(tf.zeros([784, 10]))			# 模型权重
  b = tf.Variable(tf.zeros([10]))				# 模型偏置
  y = tf.matmul(x, W) + b						# 推理操作
  y_ = tf.placeholder(tf.float32, [None, 10]) 	# 图像标签
  # 使用交叉熵作为损失值
  cross_entropy = tf.reduce_mean(
      tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))
  # 创建梯度下降优化器
  optimizer = tf.train.GradientDescentOptimizer(FLAGS.learning_rate)
  # 定义单步训练操作
  train_op = optimizer.minimize(cross_entropy)
```

这段代码的工作流程简述如下：

首先，我们从命令行解析MNIST数据目录参数，并将其保存在FLAGS名字空间中。后续代码可以通过FLAGS.data_dir属性获取这一参数。

然后，我们从数据目录中读取MNIST数据集。深度学习和机器学习算法使用的数据集通常可以根据用途划分为训练集、验证集和测试集。在TensorFlow附带的数据集处理代码中，MNIST数据集的分类和保存分别由tensorflow/contrib/learn/python/learn/datasets/mnist.py文件定义的read_data_sets方法和DataSet类实现。其中，read_data_sets方法负责解析MNIST数据集，并将其划分为训练集、验证集和测试集，分别保存到各自的DataSet实例中。DataSet类提供next_batch成员方法。当用户在会话中向占位符填充数据时，可以通过这一方法从DataSet实例中获取批数据。为了统一管理MNIST的3个数据集，tensorflow/contrib/learn/python/learn/datasets/base.py文件利用namedtuple定义了DataSets元组：`Datasets = collections.namedtuple('Datasets', ['train', 'validation', 'test'])`。本例中，read_data_sets方法返回一个名为mnist的DataSets元组，用户可以调用mnist.train成员访问MNIST训练集。

接着，我们依次创建手写体数字图像的占位符、保存模型权重和偏置的变量、前向图的推理操作、手写体数字标签的占位符、用作损失值的交叉熵，以及梯度下降优化器。其中，手写体数字标签是长度为10的one-hot向量，向量的10个分量分别对应0-9这10个数字。10个分量中只有一个值为1，其余值为0。值为1的分量的下标即是对应的手写体数字。例如，`[0,0,0,0,0,0,0,0,0,1]`表示该数字为9。

最后，我们将最小化损失值的计算操作定义为单步训练操作。训练操作汇聚了模型单步训练的所有操作，我们通常将其命名为train_op或train_step。上述步骤中的各个操作都是训练操作的前置依赖。如果我们已经得到一个训练好的模型，那就不需要定义交叉熵和优化器，直接执行推理操作即可。推理操作汇聚了模型单步推理的所有操作，我们通常将其命名为inference_op或inference_step。因为推理操作的输出张量正好是模型输出，所以我们也可以将其直接命名为y。需要注意的是，上面代码创建的推理操作`y = matmul(x,W)+b`并不是MNIST softmax模型的最终输出，MNIST softmax模型的完整的推理操作应该是`y = softmax(matmul(x,W)+b)`。为了提升计算效率，我们可以使用tf.nn.softmax_cross_entropy_with_logits操作，将softmax函数合并到交叉熵的归约计算中。代码如下所示。

```python
cross_entropy = tf.reduce_mean(
    tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))
```

如果不希望合并softmax函数，那么也可以分别定义推理操作和交叉熵。代码如下所示。

```python
y = tf.nn.softmax(tf.matmul(x, W) + b)
y_ = tf.placeholder(tf.float32, [None, 10])
cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(tf.nn.softmax(y)),
    reduction_indices=[1]))
```

现在我们已经学会了创建数据流图的方法。下面介绍如何在会话中执行训练和推理操作。

###### 5.1.4 创建单机会话

创建并运行单机会话是使用TensorFlow单机程序编程框架的第二个关键步骤。这些操作具体包括变量初始化操作、模型的恢复和保存操作、单步推理和单步训练操作等。为了执行数据流图中的操作，我们需要首先创建单机会话实例。

TensorFlow会话根据运行时形态的不同，分为单机会话（DirectSession）和分布式会话（GrpcSeesion）。两者都是基于BaseSession类实现的。在BaseSession类的构造方法中，创建会话实例是通过调用C API定义的TF_NewSession方法实现的。下面是tensorflow/python/client/session.py文件定义的BaseSession类构造方法的代码，我们摘取出创建会话的关键部分。

```python
from tensorflow.python import pywrap_tensorflow as tf_session

class BaseSession(SessionInterface):
  def __init__(self, target='', graph=None, config=None):
    # ...省略数据流图加载和会话配置过程...
    self._session = None
    opts = tf_session.TF_NewSessionOptions(target=self._target, config=config)
    try:
      with errors.raise_exception_on_not_ok_status() as status:
        # 使用C API中定义的TF_NewSession方法创建实例
        self._session = tf_session.TF_NewSession(opts, status)
    finally:
      tf_session.TF_DeleteSessionOptions(opts)
```

在创建会话时，C API定义的统一入口方法不能感知上层Python API中会话类的类型。为了区分单机和分布式会话，BaseSession类的构造方法需要将输入参数target传入C API的TF_NewSession方法。如果target为None（缺省值）或空字符串，则创建单机会话；如果target被赋予gRPC服务的URL，则创建分布式会话。因此，我们之前创建单机会话时不对target参数进行赋值。

下面我们以将上一小节介绍的MNIST softmax模型为例，展示单机会话的创建流程。首先，将MNIST softmax模型的数据流图加载到新建的单机会话中。接着，初始化全局变量，设置最大训练步数为1000步。在每一步迭代训练时，都从预处理的MNIST数据集中取出一批手写体图像数据batch_xs和标签数据batch_ys，并分别填充到对应的占位符x和y\_中。以下代码展示了在会话中不断执行单步训练操作的详细过程。

```python
# 创建Saver
saver = tf.train.Saver()
sess = tf.InteractiveSession()
tf.global_variables_initializer().run()
# 最大训练步数
for i in range(1000):
  batch_xs, batch_ys = mnist.train.next_batch(100)
  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})
  # 每100步保存一次模型参数
  if i % 100 = 0:
    saver.save(sess, 'mnist.ckpt')
correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
print('acc=%s' % sess.run(accuracy,
                          feed_dict={x: mnist.test.images,
                                     y_: mnist.test.labels}))
```

当我们调用`sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})`语句执行单步训练操作时，程序内部首先提取单步训练操作依赖的所有前置操作。这些操作的节点共同组成一幅子图。然后，程序会将子图中的计算节点、存储节点和数据节点按照各自的执行设备分类，相同设备上的节点组成了一幅局部图。每个设备上的局部图在实际执行时，根据节点间的依赖关系将各个节点有序地加载到设备上执行。对于单机程序来说，相同机器上不同编号的CPU或GPU就是不同的设备，我们可以在创建节点时指定执行该节点的设备。下面的代码展示了如何使用tf.device方法指定节点的执行设备。

```python
# 在0号CPU执行的存储节点
with tf.device("/cpu:0"):
  v = tf.Variable(...)
# 在0号GPU执行的计算节点
with tf.device("/gpu:0"):
  z = tf.matmul(x, y)
```

同时，tf.device方法也支持嵌套使用。如果我们希望把计算量小的存储节点和数据节点放在CPU上执行，把计算量大的计算节点放在GPU上执行，那么可以参考下面的代码实现。

```python
with tf.device("/cpu:0"):
  x = tf.placeholder(...)
  w = tf.Variable(...)
  b = tf.Variable(...)
  with tf.device("/gpu:0"):
    y = tf.matmul(w,x) + b
```

本例中，我们没有使用之前保存的模型参数继续训练，而是直接调用tf.global_variables_initilizer方法初始化所有的模型参数。如果想要从checkpoint文件中恢复模型参数继续训练，还需要在训练开始前调用Saver对象的restore成员方法恢复模型参数值。为此添加的代码如下所示：

```python
saver.restore(sess, 'mnist.ckpt')
for i in range(1000):
  # ...训练模型...
```

restore方法内部调用了变量的assign方法，继而更新了变量中的模型参数值。随着迭代训练步数的增加，损失值不断减小，模型在训练集上预测的准确率也会逐渐上升。训练结束后，我们需要评估模型是否在训练数据集上过拟合。于是，我们新建正确预测个数（correct_prediction）和准确率（accuracy）两个操作，然后计算模型在测试数据集上的真实值和推理值的差异，以便考察模型在测试数据集上的准确率，检验模型的泛化能力。程序运行后，得到下面展示的输出结果。可以看出，MNIST softmax模型在测试集上获得了91.61%的准确率。

```shell
Extracting /tmp/mnist-data/train-images-idx3-ubyte.gz
Extracting /tmp/mnist-data/train-labels-idx1-ubyte.gz
Extracting /tmp/mnist-data/t10k-images-idx3-ubyte.gz
Extracting /tmp/mnist-data/t10k-labels-idx1-ubyte.gz
acc=0.9161
```

综上，我们以MNIST softmax模型为例，详细地介绍了使用TensorFlow单机程序编程框架的关键步骤。通过编程实践，我们深入理解了TensorFlow单机程序开发流程中的两个核心对象——数据流图与会话。前者是算法模型的载体，后者为模型提供了运行环境。如果读者想要独立实现单机运行的深度学习和机器学习模型，那么可以参考本节的编程框架进行设计和开发。
